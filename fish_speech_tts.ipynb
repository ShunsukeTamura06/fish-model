{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio\n",
    "from loguru import logger\n",
    "\n",
    "# Fish Speechコンポーネントのインポート\n",
    "from fish_speech.inference_engine import TTSInferenceEngine\n",
    "from fish_speech.models.text2semantic.inference import launch_thread_safe_queue\n",
    "from fish_speech.models.vqgan.inference import load_model as load_decoder_model\n",
    "from fish_speech.utils.schema import ServeTTSRequest, ServeReferenceAudio\n",
    "\n",
    "class FishSpeechTTS:\n",
    "    def __init__(\n",
    "        self,\n",
    "        llama_checkpoint_path=\"checkpoints/fish-speech-1.5\",\n",
    "        decoder_checkpoint_path=\"checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\",\n",
    "        decoder_config_name=\"firefly_gan_vq\",\n",
    "        device=\"cuda\",\n",
    "        half=False,\n",
    "        compile=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Fish Speech TTSエンジンを初期化します。\n",
    "        \n",
    "        引数:\n",
    "            llama_checkpoint_path (str): LLaMAモデルのチェックポイントパス\n",
    "            decoder_checkpoint_path (str): デコーダーモデルのチェックポイントパス\n",
    "            decoder_config_name (str): デコーダー設定の名前\n",
    "            device (str): モデルを実行するデバイス ('cuda'または'cpu')\n",
    "            half (bool): 半精度（FP16）を使用するかどうか\n",
    "            compile (bool): モデルをコンパイルするかどうか\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.precision = torch.half if half else torch.bfloat16\n",
    "        self.compile = compile\n",
    "        \n",
    "        # MPSまたはCUDAが利用可能かチェックし、デバイスを調整\n",
    "        if torch.backends.mps.is_available():\n",
    "            self.device = \"mps\"\n",
    "            logger.info(\"MPSが利用可能です。MPSで実行します。\")\n",
    "        elif not torch.cuda.is_available() and device == \"cuda\":\n",
    "            logger.info(\"CUDAが利用できません。CPUで実行します。\")\n",
    "            self.device = \"cpu\"\n",
    "            \n",
    "        logger.info(\"LLaMAモデルを読み込んでいます...\")\n",
    "        self.llama_queue = launch_thread_safe_queue(\n",
    "            checkpoint_path=llama_checkpoint_path,\n",
    "            device=self.device,\n",
    "            precision=self.precision,\n",
    "            compile=self.compile,\n",
    "        )\n",
    "        \n",
    "        logger.info(\"VQ-GANモデルを読み込んでいます...\")\n",
    "        self.decoder_model = load_decoder_model(\n",
    "            config_name=decoder_config_name,\n",
    "            checkpoint_path=decoder_checkpoint_path,\n",
    "            device=self.device,\n",
    "        )\n",
    "        \n",
    "        logger.info(\"推論エンジンを作成しています...\")\n",
    "        self.inference_engine = TTSInferenceEngine(\n",
    "            llama_queue=self.llama_queue,\n",
    "            decoder_model=self.decoder_model,\n",
    "            precision=self.precision,\n",
    "            compile=self.compile,\n",
    "        )\n",
    "        \n",
    "        # ウォームアップ実行\n",
    "        logger.info(\"ウォームアップ中...\")\n",
    "        list(\n",
    "            self.inference_engine.inference(\n",
    "                ServeTTSRequest(\n",
    "                    text=\"Hello world.\",\n",
    "                    references=[],\n",
    "                    reference_id=None,\n",
    "                    max_new_tokens=1024,\n",
    "                    chunk_length=200,\n",
    "                    top_p=0.7,\n",
    "                    repetition_penalty=1.5,\n",
    "                    temperature=0.7,\n",
    "                    format=\"wav\",\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        logger.info(\"TTSエンジンの準備ができました！\")\n",
    "    \n",
    "    def text_to_speech(\n",
    "        self,\n",
    "        text,\n",
    "        reference_id=None,\n",
    "        reference_audio=None,\n",
    "        reference_text=\"\",\n",
    "        max_new_tokens=1024,\n",
    "        chunk_length=200,\n",
    "        top_p=0.7,\n",
    "        repetition_penalty=1.2,\n",
    "        temperature=0.7,\n",
    "        seed=None,\n",
    "        use_memory_cache=\"on\",\n",
    "        return_numpy=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        テキストを音声に変換します。\n",
    "        \n",
    "        引数:\n",
    "            text (str): 音声に変換するテキスト\n",
    "            reference_id (str, optional): 声のクローニングのための参照ID\n",
    "            reference_audio (str or bytes, optional): 参照音声ファイルのパスまたは音声バイト\n",
    "            reference_text (str, optional): 参照音声のためのテキスト\n",
    "            max_new_tokens (int): 生成する最大トークン数\n",
    "            chunk_length (int): 合成のためのチャンク長\n",
    "            top_p (float): Top-pサンプリングパラメータ\n",
    "            repetition_penalty (float): 繰り返しペナルティ\n",
    "            temperature (float): サンプリングの温度\n",
    "            seed (int, optional): 再現性のためのシード\n",
    "            use_memory_cache (str): メモリキャッシュを使用するかどうか（'on'または'off'）\n",
    "            return_numpy (bool): numpy配列またはAudioオブジェクトを返すかどうか\n",
    "            \n",
    "        戻り値:\n",
    "            Audio または tuple: IPython.display.Audioオブジェクトまたはタプル（サンプルレート, 音声配列）\n",
    "        \"\"\"\n",
    "        references = []\n",
    "        if reference_audio:\n",
    "            if isinstance(reference_audio, str):\n",
    "                # ファイルパスと仮定\n",
    "                with open(reference_audio, \"rb\") as f:\n",
    "                    audio_bytes = f.read()\n",
    "            else:\n",
    "                # すでにバイトデータと仮定\n",
    "                audio_bytes = reference_audio\n",
    "                \n",
    "            references = [ServeReferenceAudio(audio=audio_bytes, text=reference_text)]\n",
    "        \n",
    "        req = ServeTTSRequest(\n",
    "            text=text,\n",
    "            reference_id=reference_id,\n",
    "            references=references,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            chunk_length=chunk_length,\n",
    "            top_p=top_p,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            temperature=temperature,\n",
    "            seed=seed,\n",
    "            use_memory_cache=use_memory_cache,\n",
    "            format=\"wav\",\n",
    "        )\n",
    "        \n",
    "        for result in self.inference_engine.inference(req):\n",
    "            if result.code == \"final\":\n",
    "                sample_rate, audio_data = result.audio\n",
    "                if return_numpy:\n",
    "                    return sample_rate, audio_data\n",
    "                else:\n",
    "                    return Audio(audio_data, rate=sample_rate)\n",
    "            elif result.code == \"error\":\n",
    "                raise RuntimeError(f\"TTSでエラーが発生しました: {result.error}\")\n",
    "        \n",
    "        raise RuntimeError(\"音声が生成されませんでした\")\n",
    "\n",
    "# ノートブックでの使用例\n",
    "# テストするには以下の行をコメント解除してください\n",
    "\n",
    "# tts = FishSpeechTTS(\n",
    "#     llama_checkpoint_path=\"checkpoints/fish-speech-1.5\",\n",
    "#     decoder_checkpoint_path=\"checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n",
    "# )\n",
    "\n",
    "# # 簡単なTTSの例\n",
    "# sample_rate, audio = tts.text_to_speech(\"こんにちは、これはFish Speechテキスト読み上げのテストです。\")\n",
    "# Audio(audio, rate=sample_rate)\n",
    "\n",
    "# # 参照音声を使った声のクローニング\n",
    "# # sample_rate, audio = tts.text_to_speech(\n",
    "# #     \"こんにちは、私はクローンされた声で新しいことを言っています。\",\n",
    "# #     reference_audio=\"path/to/reference.wav\",\n",
    "# #     reference_text=\"これは声のクローニングのための参照音声です。\"\n",
    "# # )\n",
    "# # Audio(audio, rate=sample_rate)\n",
    "\n",
    "# # 生成された音声をファイルに保存\n",
    "# # import soundfile as sf\n",
    "# # sf.write(\"output.wav\", audio, sample_rate)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
